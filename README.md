# Nugen Evaluations

This repository contains evaluation reports produced by Nugen Intelligence for various AI models across different domains.

## Repository Structure

The repository is organized by domains, with each domain containing specific evaluations:

- **domain/legal/AIBE**: Evaluation of Courteasy-v1 and other leading AI models on the All India Bar Examination (AIBE)

## Available Evaluations

### Legal Domain

#### Courteasy-v1: First AI to Pass the Indian Bar Exam

A comprehensive evaluation of Courteasy-v1, an AI model developed by Nugen Intelligence specifically for Indian legal applications. The evaluation compares Courteasy-v1 with other leading models (DeepSeek-r1, GPT-4.1, and Llama-3.1-405B) on their performance in the All India Bar Examination (AIBE).

Key findings:
- Courteasy-v1 achieved 87% accuracy on AIBE-18 and 73.1% on AIBE-19, significantly exceeding the 45% passing threshold required for human legal practitioners
- The model demonstrated superior performance in criminal law and knowledge of both established Indian legal codes and recent legislative changes
- Courteasy-v1 consistently employs Indian-style legal citations, indigenous terminology, and appropriate statutory references

**Available Resources:**
- [Evaluation Report (Full)](domain/legal/AIBE/Evaluation-Report.md)
- [Evaluation Sheet (AIBE-18)](domain/legal/AIBE/AIBE-18.csv)
- [Evaluation Sheet (AIBE-19)](domain/legal/AIBE/AIBE-19.csv)

